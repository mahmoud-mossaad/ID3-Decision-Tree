{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Question #1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the needed libraries ti handle the data and do the calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from math import log\n",
    "import operator\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building up a smale dataset with 14 rows in totall and 5 features with 1 ouput\n",
    "### to start building the ID3 tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "    early_registeration  finished_homework  senior  likes_coffe  \\\n0                     1                  1       0            0   \n1                     1                  1       1            0   \n2                     0                  0       1            0   \n3                     0                  1       1            0   \n4                     0                  1       1            0   \n5                     0                  0       1            1   \n6                     1                  0       0            0   \n7                     0                  1       0            1   \n8                     0                  0       1            0   \n9                     1                  0       0            0   \n10                    1                  1       1            0   \n11                    0                  1       1            1   \n12                    0                  0       0            0   \n13                    1                  0       0            1   \n\n    liked_the_last_homework  a  \n0                         1  1  \n1                         1  1  \n2                         0  0  \n3                         1  0  \n4                         0  1  \n5                         1  1  \n6                         1  0  \n7                         1  1  \n8                         1  1  \n9                         0  0  \n10                        0  1  \n11                        1  0  \n12                        1  0  \n13                        0  1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>early_registeration</th>\n      <th>finished_homework</th>\n      <th>senior</th>\n      <th>likes_coffe</th>\n      <th>liked_the_last_homework</th>\n      <th>a</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "data = {'early_registeration':[1,1,0,0,0,0,1,0,0,1,1,0,0,1], 'finished_homework':[1,1,0,1,1,0,0,1,0,0,1,1,0,0], 'senior':[0,1,1,1,1,1,0,0,1,0,1,1,0,0], 'likes_coffe':[0,0,0,0,0,1,0,1,0,0,0,1,0,1], 'liked_the_last_homework':[1,1,0,1,0,1,1,1,1,0,0,1,1,0], 'a':[1,1,0,0,1,1,0,1,1,0,1,0,0,1]}\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The ID3 decision tree mainly depends on calculating the information gain of each feature and by selecting the maximum gain from all the features we specify the feature corresponding to that gain as the node of the current position for further tree expansion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The information gain is measured by calculating the entropy of the class which is the indication of how much information does this feature (\"Senior\" for example) have to describe the output (A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "Gain(S,F) = Entropy - \\sum_{v \\in Values(F)} \\frac{\\lvert{S_v}\\rvert}{\\lvert{S}\\rvert} Entropy(S_v) \\\\\n",
    "\\\\\n",
    "Entropy(decision) = P_+ log_2 P_+ + P_- log_2 P_- \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First we have to calculate the output entropy first since it's gonna be used with all the features and won't change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_main_class_entropy(df):\n",
    "    class_count = dict()\n",
    "    class_prob = []\n",
    "    class_entropy = 0.0\n",
    "    for i in range(len(df.a.unique())):\n",
    "        class_count[df.a.unique()[i]] = len(df[df.a == df.a.unique()[i]])\n",
    "        class_prob.append(class_count[df.a.unique()[i]]/len(df))\n",
    "    for i in range(len(class_prob)):\n",
    "        class_entropy += -(class_prob[i])*log(class_prob[i],len(class_prob))\n",
    "    #print(class_count)\n",
    "    return class_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9852281360342516"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "class_entropy = get_main_class_entropy(df)\n",
    "class_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In order to get the entropy of each feature, first of all we have to describe each feature and count the contribution of each of it's classes with the output in order to calculate the probability and the entropy later on\n",
    "### We represent the features and their counts as a dictionary the key is the feature's name and the values are as follows **The count of the first claas**, **The count of the second class**, **The count of the first class regarding the \"0\" output**, **The count of the first class regarding the \"1\" output**, **The count of the second class regarding the \"0\" output**, **The count of the second class regarding the \"1\" output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'early_registeration': [8, 6, 4, 4, 2, 4], 'finished_homework': [7, 7, 4, 3, 2, 5], 'senior': [6, 8, 3, 3, 3, 5], 'likes_coffe': [10, 4, 5, 5, 1, 3], 'liked_the_last_homework': [5, 9, 2, 3, 4, 5]}\n"
    }
   ],
   "source": [
    "features = dict()\n",
    "\n",
    "# first major class count, second major class count, first first minor class count, first second minor class count,\n",
    "# second first minor class count, second second minor class count\n",
    "for i in range(df.shape[1]-1):\n",
    "    first_class = df[df[df.iloc[:,i].name] == 0]\n",
    "    first_class_first_class = first_class[first_class[first_class.iloc[:,-1].name] == 0]\n",
    "    first_class_secound_class = first_class[first_class[first_class.iloc[:,-1].name] == 1]\n",
    "    second_class = df[df[df.iloc[:,i].name] == 1]\n",
    "    second_class_first_class = second_class[second_class[second_class.iloc[:,-1].name] == 0]\n",
    "    second_class_second_class = second_class[second_class[second_class.iloc[:,-1].name] == 1]\n",
    "\n",
    "    features[df.iloc[:,i].name] = [len(first_class), len(second_class), len(first_class_first_class), len(first_class_secound_class), len(second_class_first_class), len(second_class_second_class)]\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then we calculate the entropy of each class based on the dictionary made upove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entropy(values):\n",
    "    #print(values)\n",
    "    if values[2] != 0:\n",
    "        first_entropy = -(values[2]/values[0])*log(values[2]/values[0], 2)\n",
    "    else:\n",
    "        first_entropy = 0\n",
    "    if values[3] != 0:\n",
    "        first_entropy += -(values[3]/values[0])*log(values[3]/values[0], 2)\n",
    "    else:\n",
    "        first_entropy += 0\n",
    "    if values[4] != 0:\n",
    "        second_entropy = -(values[4]/values[1])*log(values[4]/values[1], 2)\n",
    "    else:\n",
    "        second_entropy = 0\n",
    "    if values[5] != 0:\n",
    "        second_entropy += -(values[5]/values[1])*log(values[5]/values[1], 2)\n",
    "    else:\n",
    "        second_entropy+= 0\n",
    "    return first_entropy, second_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "Entropy(decision) = P_+ log_2 P_+ + P_- log_2 P_- \\\\\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'early_registeration': [1.0, 0.9182958340544896], 'finished_homework': [0.9852281360342516, 0.863120568566631], 'senior': [1.0, 0.9544340029249649], 'likes_coffe': [1.0, 0.8112781244591328], 'liked_the_last_homework': [0.9709505944546686, 0.9910760598382222]}\n"
    }
   ],
   "source": [
    "entropy = dict()\n",
    "for i in range(len(features)):\n",
    "    first_ent, second_ent = get_entropy(features[list(features.keys())[i]])\n",
    "    entropy[list(features.keys())[i]] = [first_ent, second_ent]\n",
    "print(entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next we calculate the gain of each feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "Gain(S,F) = Entropy - \\sum_{v \\in Values(F)} \\frac{\\lvert{S_v}\\rvert}{\\lvert{S}\\rvert} Entropy(S_v) \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'early_registeration': 0.02024420715375619, 'finished_homework': 0.06105378373381032, 'senior': 0.011265848648557397, 'likes_coffe': 0.03914867190307081, 'liked_the_last_homework': 0.0013397424044413464}\n"
    }
   ],
   "source": [
    "gain = dict()\n",
    "for i in range(len(entropy)):\n",
    "    feature_gain = class_entropy - (features[list(features.keys())[i]][0]/len(df))*entropy[list(entropy.keys())[i]][0] - (features[list(features.keys())[i]][1]/len(df))*entropy[list(entropy.keys())[i]][1]\n",
    "    gain[list(features.keys())[i]] = feature_gain\n",
    "print(gain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the maximum gain we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Maximum gain is: 0.06105378373381032\nThe best feature is: finished_homework\n"
    }
   ],
   "source": [
    "print('Maximum gain is:',gain[max(gain.keys(), key=(lambda k: gain[k]))])\n",
    "print('The best feature is:', max(gain.keys(), key=(lambda k: gain[k])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To wrap it all in one function we get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_feature(df):\n",
    "\n",
    "    class_entropy = get_main_class_entropy(df)\n",
    "    #print(class_entropy)\n",
    "\n",
    "    features = dict()\n",
    "\n",
    "    # first major class count, second major class count, first first minor class count, first second minor class count,\n",
    "    # second first minor class count, second second minor class count\n",
    "    for i in range(df.shape[1]-1):\n",
    "        first_class = df[df[df.iloc[:,i].name] == 0]\n",
    "        first_class_first_class = first_class[first_class[first_class.iloc[:,-1].name] == 0]\n",
    "        first_class_secound_class = first_class[first_class[first_class.iloc[:,-1].name] == 1]\n",
    "        second_class = df[df[df.iloc[:,i].name] == 1]\n",
    "        second_class_first_class = second_class[second_class[second_class.iloc[:,-1].name] == 0]\n",
    "        second_class_second_class = second_class[second_class[second_class.iloc[:,-1].name] == 1]\n",
    "\n",
    "        features[df.iloc[:,i].name] = [len(first_class), len(second_class), len(first_class_first_class), len(first_class_secound_class), \n",
    "        len(second_class_first_class), len(second_class_second_class)]\n",
    "\n",
    "    entropy = dict()\n",
    "    for i in range(len(features)):\n",
    "        first_ent, second_ent = get_entropy(features[list(features.keys())[i]])\n",
    "        entropy[list(features.keys())[i]] = [first_ent, second_ent]\n",
    "\n",
    "    gain = dict()\n",
    "    for i in range(len(entropy)):\n",
    "        feature_gain = class_entropy - (features[list(features.keys())[i]][0]/len(df))*entropy[list(entropy.keys())[i]][0] - (features[list(features.keys())[i]][1]/len(df))*entropy[list(entropy.keys())[i]][1]\n",
    "        gain[list(features.keys())[i]] = feature_gain\n",
    "    #print(gain)\n",
    "    print(\"Gain =\" , gain[max(gain.keys(), key=(lambda k: gain[k]))])\n",
    "    return max(gain.keys(), key=(lambda k: gain[k])), features[max(gain.keys(), key=(lambda k: gain[k]))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following function represents a small implementation of the ID3 tree algorithm which represents the full statistics of the features and best feature and also we can pass the depth we want for the tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's different in the following function is that we have a new reduced dataset at each node where the tree expands, this reduction is due to removing the corresponding feature within the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree(df, levels):\n",
    "    if levels == 1:\n",
    "        feature, feature_info = get_best_feature(df)\n",
    "        print(\"The best feature to split upon is: \", feature)\n",
    "        print(feature, ': has',feature_info[0], 'in class 0' )\n",
    "        print(feature, ': has',feature_info[1], 'in class 1' )\n",
    "        print('class 0 has ', feature_info[2], 'of 0 classifications')\n",
    "        print('class 0 has ', feature_info[3], 'of 1 classifications')\n",
    "        print('class 1 has ', feature_info[4], 'of 0 classifications')\n",
    "        print('class 1 has ', feature_info[5], 'of 1 classifications')\n",
    "\n",
    "        classification_0 = feature_info[2:3].index(max([feature_info[2], feature_info[3]]))\n",
    "        classification_1 = feature_info[4:].index(max([feature_info[4], feature_info[5]]))\n",
    "        classification_0 += 2\n",
    "        classification_1 += 4\n",
    "\n",
    "        if classification_0 == 2:\n",
    "            print(\"When it's 0, Prediction is 0\")\n",
    "        if classification_0 == 3:\n",
    "            print(\"When it's 1, Prediction is 1\")\n",
    "        if classification_1 == 4:\n",
    "            print(\"When it's 0, Prediction is 0\")\n",
    "        if classification_1 == 5:\n",
    "            print(\"When it's 1, Prediction is 1\")\n",
    "        print(\"###############################\")\n",
    "    if levels == 2:\n",
    "        print(\"This is the first LEVEL\")\n",
    "        print(\"..............................\")\n",
    "        feature, feature_info = get_best_feature(df)\n",
    "        print(feature, ': has',feature_info[0], 'in class 0' )\n",
    "        print(feature, ': has',feature_info[1], 'in class 1' )\n",
    "        print('class 0 has ', feature_info[2], 'of 0 classifications')\n",
    "        print('class 0 has ', feature_info[3], 'of 1 classifications')\n",
    "        print('class 1 has ', feature_info[4], 'of 0 classifications')\n",
    "        print('class 1 has ', feature_info[5], 'of 1 classifications')\n",
    "\n",
    "        classification_0 = feature_info[2:3].index(max([feature_info[2], feature_info[3]]))\n",
    "        classification_1 = feature_info[4:].index(max([feature_info[4], feature_info[5]]))\n",
    "        classification_0 += 2\n",
    "        classification_1 += 4\n",
    "\n",
    "        if classification_0 == 2:\n",
    "            print(\"When it's 0, Prediction is 0\")\n",
    "        if classification_0 == 3:\n",
    "            print(\"When it's 1, Prediction is 1\")\n",
    "        if classification_1 == 4:\n",
    "            print(\"When it's 0, Prediction is 0\")\n",
    "        if classification_1 == 5:\n",
    "            print(\"When it's 1, Prediction is 1\")\n",
    "\n",
    "        # Dropping the features that was exracted and passing the new dataset to the next nodes    \n",
    "        df1 = df[df[feature] == 0].drop(columns=[feature])\n",
    "        df2 = df[df[feature] == 1].drop(columns=[feature])\n",
    "        \n",
    "        print(\"###############################\")\n",
    "        ###############################\n",
    "        print(\"This is the second LEVEL\")\n",
    "        print(\"..............................\")\n",
    "        feature, feature_info = get_best_feature(df1)\n",
    "        print(feature, ': has',feature_info[0], 'in class 0' )\n",
    "        print(feature, ': has',feature_info[1], 'in class 1' )\n",
    "        print('class 0 has ', feature_info[2], 'of 0 classifications')\n",
    "        print('class 0 has ', feature_info[3], 'of 1 classifications')\n",
    "        print('class 1 has ', feature_info[4], 'of 0 classification')\n",
    "        print('class 1 has ', feature_info[5], 'of 1 classification')\n",
    "\n",
    "        classification_0 = feature_info[2:3].index(max([feature_info[2], feature_info[3]]))\n",
    "        classification_1 = feature_info[4:].index(max([feature_info[4], feature_info[5]]))\n",
    "        classification_0 += 2\n",
    "        classification_1 += 4\n",
    "\n",
    "        if classification_0 == 2:\n",
    "            print(\"When it's 0, Prediction is 0\")\n",
    "        if classification_0 == 3:\n",
    "            print(\"When it's 1, Prediction is 1\")\n",
    "        if classification_1 == 4:\n",
    "            print(\"When it's 0, Prediction is 0\")\n",
    "        if classification_1 == 5:\n",
    "            print(\"When it's 1, Prediction is 1\")\n",
    "        ###############################\n",
    "        print(\"###############################\")\n",
    "        feature, feature_info = get_best_feature(df2)\n",
    "        print(feature, ': has',feature_info[0], 'in class 0' )\n",
    "        print(feature, ': has',feature_info[1], 'in class 1' )\n",
    "        print('class 0 has ', feature_info[2], 'of 0 classifications')\n",
    "        print('class 0 has ', feature_info[3], 'of 1 classifications')\n",
    "        print('class 1 has ', feature_info[4], 'of 0 classifications')\n",
    "        print('class 1 has ', feature_info[5], 'of 1 classifications')\n",
    "        \n",
    "        \n",
    "\n",
    "        classification_0 = feature_info[2:3].index(max([feature_info[2], feature_info[3]]))\n",
    "        classification_1 = feature_info[4:].index(max([feature_info[4], feature_info[5]]))\n",
    "        classification_0 += 2\n",
    "        classification_1 += 4\n",
    "        \n",
    "        if classification_0 == 2:\n",
    "            print(\"When it's 0, Prediction is 0\")\n",
    "        if classification_0 == 3:\n",
    "            print(\"When it's 1, Prediction is 1\")\n",
    "        if classification_1 == 4:\n",
    "            print(\"When it's 0, Prediction is 0\")\n",
    "        if classification_1 == 5:\n",
    "            print(\"When it's 1, Prediction is 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So now by simply passing the whole data to the upove wrapped up function and passing the depth level we get the below results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Gain =0.06105378373381032\nThe best feature to split upon is:  finished_homework\nfinished_homework : has 7 in class 0\nfinished_homework : has 7 in class 1\nclass 0 has  4 of 0 classifications\nclass 0 has  3 of 1 classifications\nclass 1 has  2 of 0 classifications\nclass 1 has  5 of 1 classifications\nWhen it's 0, Prediction is 0\nWhen it's 1, Prediction is 1\n###############################\n"
    }
   ],
   "source": [
    "decision_tree(df, 1) # For depth of one, which means only the root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](depth1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "This is the first LEVEL\n..............................\nGain = 0.06105378373381032\nfinished_homework : has 7 in class 0\nfinished_homework : has 7 in class 1\nclass 0 has  4 of 0 classifications\nclass 0 has  3 of 1 classifications\nclass 1 has  2 of 0 classifications\nclass 1 has  5 of 1 classifications\nWhen it's 0, Prediction is 0\nWhen it's 1, Prediction is 1\n###############################\nThis is the second LEVEL\n..............................\nGain = 0.46956521111470706\nlikes_coffe : has 5 in class 0\nlikes_coffe : has 2 in class 1\nclass 0 has  4 of 0 classifications\nclass 0 has  1 of 1 classifications\nclass 1 has  0 of 0 classification\nclass 1 has  2 of 1 classification\nWhen it's 0, Prediction is 0\nWhen it's 1, Prediction is 1\n###############################\nGain = 0.2916919971380596\nearly_registeration : has 4 in class 0\nearly_registeration : has 3 in class 1\nclass 0 has  2 of 0 classifications\nclass 0 has  2 of 1 classifications\nclass 1 has  0 of 0 classifications\nclass 1 has  3 of 1 classifications\nWhen it's 0, Prediction is 0\nWhen it's 1, Prediction is 1\n"
    }
   ],
   "source": [
    "decision_tree(df, 2) # For depth of two, which means the root and the following branches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](depth2.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}